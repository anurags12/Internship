{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13510e2-1964-409e-b030-e01a97a67d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0656fdb-8bd4-42ca-ab4e-b1bf8f29d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Automated chrome browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118a6f2-8c39-44c9-a3ed-2ee9e42690cf",
   "metadata": {},
   "source": [
    "Q1: In this question you have to scrape data using the filters available on the webpage You have to use the location and \r\n",
    "salary filter.  \r\n",
    "You have to scrape data for ‚ÄúData Scientist‚Äù designation for first 10 job results.  \r\n",
    "You have to scrape the job-title, job-location, company name, experience required.  \r\n",
    "The location filter to be used is ‚ÄúDelhi/NCR‚Äù. The salary filter to be used is ‚Äú3-6‚Äù lakhs  \r\n",
    "The task will be done as shown in the below steps:  \r\n",
    "1. first get the web page https://www.naukri.com/ \r\n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúSkill, Designations, and Companies‚Äù field.  \r\n",
    "3. Then click the search button.  \r\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes  \r\n",
    "5. Then scrape the data for the first 10 jobs results you get.  \r\n",
    "6. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d984af90-62ff-4338-82f0-2e4ebd63d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening naukri.com on automated chrome browser\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d066fafd-2875-4fad-b9de-fc8e123ff9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for data scientist roles\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2026cd69-6e07-4e44-8053-31bb19aa0fbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applying the Location Filter\n",
    "Delhi_NCR=driver.find_element(By.XPATH,'//label[@for=\"chk-Delhi / NCR-cityTypeGid-\"]/i')\n",
    "Delhi_NCR.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f11dd59-cdb9-4f69-963b-0117785c0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the Salary Filter\n",
    "three_to_six_lakhs=driver.find_element(By.XPATH,'//label[@for=\"chk-3-6 Lakhs-ctcFilter-\"]/i')\n",
    "three_to_six_lakhs.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91c6081c-a78f-428d-865c-477cd48b52ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#Scraping the data from the jobs result\n",
    "\n",
    "# Creating empty list to store the scraped data\n",
    "title=[]\n",
    "location=[]\n",
    "company=[]\n",
    "experience=[]\n",
    "\n",
    "# Scraping job_title of first 10 jobs results\n",
    "title_tag=driver.find_elements(By.XPATH,'//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/a')\n",
    "for t in title_tag[0:10]:\n",
    "    title.append(t.text)\n",
    "\n",
    "# Scraping Job_Location of first 10 jobs results\n",
    "location_tag=driver.find_elements(By.XPATH,'//span[@class=\"ni-job-tuple-icon ni-job-tuple-icon-srp-location loc\"]')\n",
    "for l in location_tag[0:10]:\n",
    "    location.append(l.text)\n",
    "\n",
    "# Scraping Company name of first 10 jobs results\n",
    "company_tag=driver.find_elements(By.XPATH,'//span[@class=\" comp-dtls-wrap\"]/a[1]')\n",
    "for c in company_tag[0:10]:\n",
    "    company.append(re.sub('\\n.*','',c.text))\n",
    "\n",
    "# Scraping Experience Requirment for first 10 jobs results\n",
    "exp_tag=driver.find_elements(By.XPATH,'//span[@class=\"ni-job-tuple-icon ni-job-tuple-icon-srp-experience exp\"]')\n",
    "for e in exp_tag[0:10]:\n",
    "    experience.append(e.text)\n",
    "\n",
    "print(len(title),len(location),len(company),len(experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daf65209-c7a4-44b9-a904-dcde64076cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist HTHD</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Ford</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram, Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - NLP, Gen AI</td>\n",
       "      <td>Noida</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Scientist - Data Sourcing &amp; Solutions</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Axa Technology Services</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Global GI Data Scientist</td>\n",
       "      <td>Faridabad</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Digital Glyde</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Wizaltia Hr Solutions</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Kmart</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>KAS Services</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job-title  \\\n",
       "0                              Data Scientist HTHD   \n",
       "1                                   Data Scientist   \n",
       "2                     Data Scientist - NLP, Gen AI   \n",
       "3  Associate Scientist - Data Sourcing & Solutions   \n",
       "4                         Global GI Data Scientist   \n",
       "5                                   Data Scientist   \n",
       "6                            Python Data Scientist   \n",
       "7                                   Data Scientist   \n",
       "8                                   Data Scientist   \n",
       "9                                   Data Scientist   \n",
       "\n",
       "                                        Job-location             Company Name  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...                     Ford   \n",
       "1                                Gurugram, Bengaluru                Blackbuck   \n",
       "2                                              Noida  R Systems International   \n",
       "3                                           Gurugram  Axa Technology Services   \n",
       "4                                          Faridabad             Hitachi Ltd.   \n",
       "5  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...            Digital Glyde   \n",
       "6  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...    Wizaltia Hr Solutions   \n",
       "7  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...                    Kmart   \n",
       "8  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...             KAS Services   \n",
       "9  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...       Scienaptic Systems   \n",
       "\n",
       "  Experience Required  \n",
       "0             1-4 Yrs  \n",
       "1             3-7 Yrs  \n",
       "2             5-8 Yrs  \n",
       "3             1-4 Yrs  \n",
       "4             3-5 Yrs  \n",
       "5             3-7 Yrs  \n",
       "6             2-7 Yrs  \n",
       "7             3-5 Yrs  \n",
       "8             3-5 Yrs  \n",
       "9             2-7 Yrs  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe of scraped data from naukri.com\n",
    "df=pd.DataFrame({'Job-title':title,'Job-location':location,'Company Name':company,'Experience Required':experience})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811c0e6-a313-4358-b228-285d0ed39d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a0c00b9-221f-4607-8540-352012c47c4f",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the \r\n",
    "job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. \r\n",
    "This task will be done in following steps: \r\n",
    "1. First get the webpage https://www.shine.com/ \r\n",
    "2. Enter ‚ÄúData Analyst‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field. \r\n",
    "3. Then click the searchbutton.  \r\n",
    "4. Then scrape the data for the first 10 jobs results you get.  \r\n",
    "5. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "328827db-73d7-40c9-ac18-544950ce7f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening shine.com on automated chrome browser\n",
    "driver.get('https://www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d3ae54f-7a00-463d-a9eb-a253f8d5c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for Data Analyst role in Bangalore on shine.com\n",
    "\n",
    "# Entering job_title\n",
    "designation=driver.find_element(By.XPATH,'//li[@class=\"searchForm_search_item__hr6Du form-group \"]/div/input')\n",
    "designation.send_keys('Data Analyst')\n",
    "\n",
    "# Entering Job_location\n",
    "loc=driver.find_element(By.ID,\"id_loc\")\n",
    "loc.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcaeb243-d24d-4dff-8925-a0b30fa7f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Search Button\n",
    "search=driver.find_element(By.XPATH,'//div[@class=\"searchForm_btnWrap__Cb75F\"]/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa1b14c7-ec91-4513-9aa6-23178fb1cae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Scraping data of search results for data analyst role in bangalore on shine.com\n",
    "\n",
    "#Creating Empty Lists to store the scraped data\n",
    "j_title=[]\n",
    "j_location=[]\n",
    "comp_name=[]\n",
    "exp_reqr=[]\n",
    "\n",
    "#Scraping job title of first 10 jobs results\n",
    "title_tag=driver.find_elements(By.XPATH,'//strong[@class=\"jobCard_pReplaceH2__xWmHg\"]')\n",
    "for t in title_tag[0:10]:\n",
    "    j_title.append(t.text)\n",
    "\n",
    "# Scraping location of first 10 jobs results\n",
    "loc_tag=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for l in loc_tag[0:10]:\n",
    "    j_location.append(re.sub('\\n.*','',l.text))\n",
    "\n",
    "#Scraping company name of first 10 jobs results\n",
    "comp_tag=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for c in comp_tag[0:10]:\n",
    "    comp_name.append(c.text)\n",
    "\n",
    "# Scraping Experience Requirement for first 10 jobs results\n",
    "exp_tag=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for e in exp_tag[0:10]:\n",
    "    exp_reqr.append(e.text)\n",
    "\n",
    "print(len(j_title),len(j_location),len(comp_name),len(exp_reqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6700cb0d-5faf-4340-8f5c-1248b32bdd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst , Senior Data Analyst , Data Anal...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>appsoft solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>valenta bpo solutions pvt. ltd.</td>\n",
       "      <td>4 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst (Power BI, Python, SQL)- Internal...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>talent leads hr solutions pvt ltd</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst Fresher and Experience Vacancy</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst Opening</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>mackenzie modern it solutions priva...</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MIS Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>quess corp (magna infotech)</td>\n",
       "      <td>8 to 13 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title Job-location  \\\n",
       "0  Data Analyst , Senior Data Analyst , Data Anal...    Bangalore   \n",
       "1                                       Data Analyst    Bangalore   \n",
       "2  Data Analyst (Power BI, Python, SQL)- Internal...    Bangalore   \n",
       "3                              Clinical Data Analyst    Bangalore   \n",
       "4        Data Analyst Fresher and Experience Vacancy    Bangalore   \n",
       "5                               Data Analyst Opening    Bangalore   \n",
       "6                           Data Analyst Recruitment    Bangalore   \n",
       "7                           Data Analyst Recruitment    Bangalore   \n",
       "8                                   Business Analyst    Bangalore   \n",
       "9                                        MIS Analyst    Bangalore   \n",
       "\n",
       "                             Company Name Experience Required  \n",
       "0                       appsoft solutions          0 to 4 Yrs  \n",
       "1         valenta bpo solutions pvt. ltd.          4 to 5 Yrs  \n",
       "2       talent leads hr solutions pvt ltd          3 to 8 Yrs  \n",
       "3                           techno endura           0 to 1 Yr  \n",
       "4                     radhika enterprises          0 to 4 Yrs  \n",
       "5                     radhika enterprises          0 to 4 Yrs  \n",
       "6                     radhika enterprises          0 to 4 Yrs  \n",
       "7                     radhika enterprises          0 to 4 Yrs  \n",
       "8  mackenzie modern it solutions priva...          4 to 6 Yrs  \n",
       "9             quess corp (magna infotech)         8 to 13 Yrs  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame of Scraped data from shine.com\n",
    "df=pd.DataFrame({'Job-title':j_title,'Job-location':j_location,'Company Name':comp_name,'Experience Required':exp_reqr})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28bbb31-de1e-4ad6-b98f-d819658a0154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87f2fa0b-407c-4954-8b6e-ecbfb22bf222",
   "metadata": {},
   "source": [
    "Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \r\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\r\n",
    "reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=\r\n",
    " LIPKAT \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "187fa8e0-2fa9-4bb7-85e7-1ab2bf45f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening iphone 11 review page on flipkart.com\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "818a54b1-99cc-4f84-a109-f3233c7efae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "# Scraping the  100 reviews for iphone 11 on flipkart.com\n",
    "\n",
    "# Creating Empty lists to store scraped data\n",
    "rating=[]\n",
    "r_summary=[]\n",
    "full_review=[]\n",
    "\n",
    "# Creating a for loop to scrap data from 10 pages\n",
    "for i in range(0,10):\n",
    "    rating_tag=driver.find_elements(By.XPATH,'//div[@class=\"XQDdHH Ga3i8K\"]') # Scraping ratings of the product\n",
    "    for r in rating_tag:\n",
    "        rating.append(r.text)\n",
    "\n",
    "    summary_tag=driver.find_elements(By.XPATH,'//p[@class=\"z9E0IG\"]')  # Scraping review summary of the product\n",
    "    for s in summary_tag:\n",
    "        r_summary.append(s.text)\n",
    "\n",
    "    fullreview_tag=driver.find_elements(By.XPATH,'//div[@class=\"ZmyHeo\"]') # Scraping full review of the product\n",
    "    for f in fullreview_tag:\n",
    "        full_review.append(f.text.replace('\\n',' '))\n",
    "\n",
    "    next=driver.find_element(By.CLASS_NAME,\"_9QVEpD\") #Moving on to the next page\n",
    "    next.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "print(len(rating),len(r_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21edac63-b384-4f91-980c-077ae6f531a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review-Summary</th>\n",
       "      <th>Full-Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome Best battery backup A perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>iPhone 11 is a good phone. Not a very big diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Good product üëåI love iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Excellent Phone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Go for iPhone 11 , if confused between iPhone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Superbb performance n camera is awesome üòçüòç</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review-Summary  \\\n",
       "0       5       Classy product   \n",
       "1       5             Terrific   \n",
       "2       5            Wonderful   \n",
       "3       5    Worth every penny   \n",
       "4       5  Best in the market!   \n",
       "..    ...                  ...   \n",
       "95      5              Awesome   \n",
       "96      5               Super!   \n",
       "97      5            Brilliant   \n",
       "98      5            Must buy!   \n",
       "99      5  Best in the market!   \n",
       "\n",
       "                                          Full-Review  \n",
       "0   Camera is awesome Best battery backup A perfor...  \n",
       "1                                      Very very good  \n",
       "2                              This is amazing at all  \n",
       "3   Feeling awesome after getting the delivery of ...  \n",
       "4                                         Good Camera  \n",
       "..                                                ...  \n",
       "95  iPhone 11 is a good phone. Not a very big diff...  \n",
       "96                        Good product üëåI love iPhone  \n",
       "97                                   Excellent Phone.  \n",
       "98  Go for iPhone 11 , if confused between iPhone ...  \n",
       "99         Superbb performance n camera is awesome üòçüòç  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame of the Scraped data from flipkart\n",
    "df=pd.DataFrame({'Rating':rating,'Review-Summary':r_summary,'Full-Review':full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005369f-5487-4eee-a418-2bb3f951bab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "788714f5-5815-48ee-a331-d9d6acfd7c4b",
   "metadata": {},
   "source": [
    "Q4: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for ‚Äúsneakers‚Äù in the search \r\n",
    "field. \r\n",
    "You have to scrape 3 attributes of each sneaker: \r\n",
    "1. Brand \r\n",
    "2. Product Description \r\n",
    "3. Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "724fdfd3-acca-4309-b05b-28050d03ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening flipkart on automated chrome browser\n",
    "\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a89239bd-6432-40bc-a0a9-dd7c7ac84b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching sneakers on flipkart\n",
    "product_field=driver.find_element(By.CLASS_NAME,\"Pke_EE\")\n",
    "product_field.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3a1ccd3-8987-4533-a1cf-3901a8a89da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on search\n",
    "search=driver.find_element(By.CLASS_NAME,\"_2iLD__\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8286fed4-8a67-492f-aa5b-e26acb16bd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 118\n"
     ]
    }
   ],
   "source": [
    "# Scraping first 100 data of the sneakers search result on flipkart\n",
    "\n",
    "# creating blank list to store the scraped data\n",
    "brand=[]\n",
    "product_descr=[]\n",
    "price=[]\n",
    "\n",
    "# scraping data from first 3 pages\n",
    "for i in range(0,3):\n",
    "    brand_tag=driver.find_elements(By.XPATH,'//div[@class=\"syl9yP\"]') # Scraping brand name of the product\n",
    "    for b in brand_tag:\n",
    "        brand.append(b.text)\n",
    "\n",
    "    descr_tag=driver.find_elements(By.XPATH,'//div[@class=\"hCKiGj\"]/a[1]') # Scraping product description\n",
    "    for d in descr_tag:\n",
    "        product_descr.append(d.text)\n",
    "\n",
    "    price_tag=driver.find_elements(By.XPATH,'//div[@class=\"Nx9bqj\"]') # Scraping Price of the product\n",
    "    for p in price_tag:\n",
    "        price.append(p.text.replace('‚Çπ',''))\n",
    "\n",
    "    next=driver.find_element(By.CLASS_NAME,\"_9QVEpD\")\n",
    "    next.click() # Moving on to the next page\n",
    "    time.sleep(10)\n",
    "\n",
    "print(len(brand),len(product_descr),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6bf9918-b79d-48ee-a7c4-99b31056b256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product-description</th>\n",
       "      <th>Price(‚Çπ)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROASTER</td>\n",
       "      <td>Stylish Multi Sports Casual Sneaker Shoes Snea...</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Trending Stylish Casual Outdoor Shoes Sneakers...</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Stylish Shoes for Girls Sneakers For Women</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Casual Sneaker Shoes for Men | Classic Rounded...</td>\n",
       "      <td>1,649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Stylish &amp; Trending Outdoor Walking Comfortable...</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Jack Diamond</td>\n",
       "      <td>sneaker Sneakers For Men</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PROVOGUE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nobelite</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                Product-description Price(‚Çπ)\n",
       "0        ROASTER  Stylish Multi Sports Casual Sneaker Shoes Snea...      317\n",
       "1      Deals4you                                 Sneakers For Women      378\n",
       "2       URBANBOX  Trending Stylish Casual Outdoor Shoes Sneakers...      299\n",
       "3         Shozie         Stylish Shoes for Girls Sneakers For Women      351\n",
       "4       RED TAPE  Casual Sneaker Shoes for Men | Classic Rounded...    1,649\n",
       "..           ...                                                ...      ...\n",
       "95      URBANBOX  Stylish & Trending Outdoor Walking Comfortable...      749\n",
       "96          aadi  Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...      749\n",
       "97  Jack Diamond                           sneaker Sneakers For Men      465\n",
       "98      PROVOGUE                                   Sneakers For Men      370\n",
       "99      Nobelite                                   Sneakers For Men      470\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame of first 100 scraped data from flipkart\n",
    "df=pd.DataFrame({'Brand':brand[0:100],'Product-description':product_descr[0:100],'Price(‚Çπ)':price[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e571bfa-6a42-4b9b-b954-f6ea5556998c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb949408-5177-45db-b77a-6728b1a75e75",
   "metadata": {},
   "source": [
    "Q5: Go to webpage https://www.amazon.in/ Enter ‚ÄúLaptop‚Äù in the search field and then click the search icon. Then set CPU \r\n",
    "Type filter to ‚ÄúIntel Core i7 After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop: \r\n",
    "1. Title \r\n",
    "2. Ratings \r\n",
    "3. Price‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c1a60c6-18ea-451d-86ca-18044f5b1c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Amazon on automated chrome\n",
    "driver.get(' https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1242ba4-62a4-4b8b-9e38-05f16e3c1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for laptop on amazon\n",
    "product=driver.find_element(By.XPATH,'//input[@id=\"twotabsearchtextbox\"]')\n",
    "product.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0219c3e7-4118-4473-918c-4376764977b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.ID,\"nav-search-submit-button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc2e8a90-2b98-403e-a120-b859b904208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting CPU filter to \"intel core i7\"\n",
    "i7=driver.find_element(By.XPATH,'//li[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/div/label/i')\n",
    "i7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5449a27f-cf9e-4da7-b162-b38ae017d3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# scraping first 10 laptop data from amazon\n",
    "\n",
    "# Creating blank list to store the scraped data\n",
    "title=[]\n",
    "rating=[]\n",
    "price=[]\n",
    "# scraping title of first 10 laptop results\n",
    "title_tag=driver.find_elements(By.XPATH,'//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]/a/span')\n",
    "for t in title_tag[0:10]:\n",
    "    title.append(t.text)\n",
    "\n",
    "# scraping rating of first 10 laptop results\n",
    "rating_tag=driver.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]/span[1]')\n",
    "for r in rating_tag[0:10]:\n",
    "    rating.append(r.get_attribute(\"aria-label\").replace('out of 5 stars',''))\n",
    "\n",
    "# scraping price of first 10 laptop results\n",
    "price_tag=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-none a-spacing-top-micro puis-price-instructions-style\"]/div/div/a/span')\n",
    "for p in price_tag[0:10]:\n",
    "    price.append(p.text.replace('‚Çπ',''))\n",
    "\n",
    "print(len(title),len(rating),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7da3114-da90-482f-b0dc-54dc6ef789b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating(Out of 5 stars)</th>\n",
       "      <th>Price(‚Çπ)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell Inspiron 7420 2in1 Laptop, Intel Core i7-...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>77,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Aspire Lite 12th Gen Intel Core i7-1255U ...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>54,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i7 11th Gen 1...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>58,250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>63,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>72,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>77,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS Vivobook 15, IntelCore i7-12650H 12th Gen...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Travelmate Business Laptop Intel Core i7-...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>47,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....</td>\n",
       "      <td>3.4</td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating(Out of 5 stars)  \\\n",
       "0  Dell Inspiron 7420 2in1 Laptop, Intel Core i7-...                   4.0    \n",
       "1  Acer Aspire Lite 12th Gen Intel Core i7-1255U ...                   3.8    \n",
       "2  MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...                   4.0    \n",
       "3  Lenovo IdeaPad Slim 3 Intel Core i7 11th Gen 1...                   3.1    \n",
       "4  HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...                   4.1    \n",
       "5  ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...                   3.5    \n",
       "6  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...                   4.4    \n",
       "7  ASUS Vivobook 15, IntelCore i7-12650H 12th Gen...                   4.2    \n",
       "8  Acer Travelmate Business Laptop Intel Core i7-...                   3.7    \n",
       "9  Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....                   3.4    \n",
       "\n",
       "  Price(‚Çπ)  \n",
       "0   77,490  \n",
       "1   54,990  \n",
       "2   54,990  \n",
       "3   58,250  \n",
       "4   63,990  \n",
       "5   72,990  \n",
       "6   77,700  \n",
       "7   57,990  \n",
       "8   47,990  \n",
       "9   59,990  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe of scraped laptop data from amazon\n",
    "df=pd.DataFrame({'Title':title,'Rating(Out of 5 stars)':rating,'Price(‚Çπ)':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9957f-c58f-4ce4-9ce5-90353a94add9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95dc5c1d-66dd-4f08-a06f-5cb02419bdff",
   "metadata": {},
   "source": [
    "Q6: Write a python program to scrape data for Top 1000 Quotes of All Time. \r\n",
    "The above task will be done in following steps: \r\n",
    "1. First get the webpagehttps://www.azquotes.com/ \r\n",
    "2. Click on Top Quote \r\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaababc8-e3be-4a85-bb46-0d98f38c1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening azquotes on automated chrome\n",
    "driver.get('https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f03e8caa-d77b-4636-ad12-a71c3250af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on top quotes\n",
    "top_quotes=driver.find_element(By.XPATH,'//div[@class=\"mainmenu\"]/ul/li[5]')\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "876b277a-8fdc-46a8-af24-5a108a529226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "# Scraping 1000 quotes data from azquote\n",
    "\n",
    "#creating blank list to store scraped data\n",
    "quote=[]\n",
    "author=[]\n",
    "type=[]\n",
    "\n",
    "#scraping data from 10 pages\n",
    "for i in range(0,10):\n",
    "    quote_tag=driver.find_elements(By.XPATH,'//div[@class=\"wrap-block\"]/p/a[2]') # scraping quotes\n",
    "    for q in quote_tag:\n",
    "        quote.append(q.text)\n",
    "\n",
    "    author_tag=driver.find_elements(By.XPATH,'//div[@class=\"author\"]') # scraping author name of the quotes\n",
    "    for a in author_tag:\n",
    "        author.append(a.text)\n",
    "\n",
    "    type_tag=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]') # scraping type of the quotes\n",
    "    for t in type_tag:\n",
    "        type.append(t.text)\n",
    "        \n",
    "    if len(quote)==1000:\n",
    "        break\n",
    "        \n",
    "    next=driver.find_element(By.XPATH,'//li[@class=\"next\"]')\n",
    "    next.click() # Moving onto the next page\n",
    "    time.sleep(20)\n",
    "\n",
    "print(len(quote),len(author),len(type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd23c8c8-c8e8-404e-963f-e877d3c3f96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Author-Name</th>\n",
       "      <th>Type of quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quotes         Author-Name  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                               Type of quotes  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe of scraped data\n",
    "df=pd.DataFrame({'Quotes':quote,'Author-Name':author,'Type of quotes':type})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a1d2a-e99c-4281-b3d6-f0e16c55ff07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cef3d4e-01f4-4b71-9b18-433ec32f3e17",
   "metadata": {},
   "source": [
    "Q7: Write a python program to display list of respected former Prime Ministers of India (i.e. Name, \r\n",
    "Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/general-knowledge/list-of\r\n",
    "all-prime-ministers-of-india-1473165149-1  \r\n",
    "scrap the mentioned data and make the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a19c8b6f-1c72-4601-b242-5dbd9c433516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the given jagaranjosh link on automated chrome\n",
    "driver.get('https://www.jagranjosh.com/general-knowledge/list-of all-prime-ministers-of-india-1473165149-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05eaa3d1-cc52-4173-a9ac-65de823ba525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 19 19 19\n"
     ]
    }
   ],
   "source": [
    "# Scraping data from given link\n",
    "\n",
    "# creating blank list to store the scraped data\n",
    "name=[]\n",
    "born_dead=[]\n",
    "office_term=[]\n",
    "remarks=[]\n",
    "\n",
    "# Scraping Prime Ministers of India Names\n",
    "name_tag=driver.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[2]/div')\n",
    "for n in name_tag:\n",
    "    name.append(n.text)\n",
    "\n",
    "# Scraping Born-Dead year of the Prime Ministers\n",
    "b_d_tag=driver.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[3]')\n",
    "for b in b_d_tag:\n",
    "    born_dead.append(re.sub('[()]','',b.text))\n",
    "\n",
    "# scraping term of office of the Prime Ministers\n",
    "term_tag=driver.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[4]')\n",
    "for t in term_tag:\n",
    "    office_term.append(t.text.replace('\\n',' '))\n",
    "\n",
    "# scraping remarks\n",
    "remark_tag=driver.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[5]')\n",
    "for r in remark_tag:\n",
    "    remarks.append(r.text)\n",
    "\n",
    "print(len(name),len(born_dead),len(office_term),len(remarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9106a00-72d0-43da-8df0-fe3b0be2f38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term of Office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>1889‚Äì1964</td>\n",
       "      <td>15 August 1947 to 27 May 1964 16 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>1898-1998</td>\n",
       "      <td>27 May 1964 to 9 June 1964, 13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>1904‚Äì1966</td>\n",
       "      <td>9 June 1964 to 11 January 1966 1 year, 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>1898-1998</td>\n",
       "      <td>11 January 1966 to 24 January 1966 13 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>1917‚Äì1984</td>\n",
       "      <td>24 January 1966 to 24 March 1977 11 years, 59 ...</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>1896‚Äì1995</td>\n",
       "      <td>24 March 1977 to  28 July 1979  2 year, 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>1902‚Äì1987</td>\n",
       "      <td>28 July 1979 to 14 January 1980 170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>1917‚Äì1984</td>\n",
       "      <td>14 January 1980 to 31 October 1984 4 years, 29...</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>1944‚Äì1991</td>\n",
       "      <td>31 October 1984 to 2 December 1989 5 years, 32...</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>1931‚Äì2008</td>\n",
       "      <td>2 December 1989 to 10 November 1990 343 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>1927‚Äì2007</td>\n",
       "      <td>10 November 1990 to 21 June 1991 223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>1921‚Äì2004</td>\n",
       "      <td>21 June 1991 to 16 May 1996 4 years, 330 days</td>\n",
       "      <td>First PM from South India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>1924- 2018</td>\n",
       "      <td>16 May 1996 to 1 June 1996 16 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>born 1933</td>\n",
       "      <td>1 June 1996 to 21 April 1997 324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>1919‚Äì2012</td>\n",
       "      <td>21 April 1997 to 19 March 1998  332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>1924-2018</td>\n",
       "      <td>19 March 1998 to 22 May 2004  6 years, 64 days</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>born 1932</td>\n",
       "      <td>22 May 2004 to 26 May 2014    10 years, 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>born 1950</td>\n",
       "      <td>26 May 2014 - 2019</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>born 1950</td>\n",
       "      <td>30 May 2019- Incumbent</td>\n",
       "      <td>First non-congress PM with two consecutive ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Born-Dead  \\\n",
       "0             Jawahar Lal Nehru   1889‚Äì1964   \n",
       "1     Gulzarilal Nanda (Acting)   1898-1998   \n",
       "2           Lal Bahadur Shastri   1904‚Äì1966   \n",
       "3   Gulzari Lal Nanda  (Acting)   1898-1998   \n",
       "4                 Indira Gandhi   1917‚Äì1984   \n",
       "5                 Morarji Desai   1896‚Äì1995   \n",
       "6                  Charan Singh   1902‚Äì1987   \n",
       "7                 Indira Gandhi   1917‚Äì1984   \n",
       "8                  Rajiv Gandhi   1944‚Äì1991   \n",
       "9                   V. P. Singh   1931‚Äì2008   \n",
       "10              Chandra Shekhar   1927‚Äì2007   \n",
       "11          P. V. Narasimha Rao   1921‚Äì2004   \n",
       "12         Atal Bihari Vajpayee  1924- 2018   \n",
       "13             H. D. Deve Gowda   born 1933   \n",
       "14           Inder Kumar Gujral   1919‚Äì2012   \n",
       "15         Atal Bihari Vajpayee   1924-2018   \n",
       "16               Manmohan Singh   born 1932   \n",
       "17                Narendra Modi   born 1950   \n",
       "18                Narendra Modi   born 1950   \n",
       "\n",
       "                                       Term of Office  \\\n",
       "0    15 August 1947 to 27 May 1964 16 years, 286 days   \n",
       "1                 27 May 1964 to 9 June 1964, 13 days   \n",
       "2     9 June 1964 to 11 January 1966 1 year, 216 days   \n",
       "3          11 January 1966 to 24 January 1966 13 days   \n",
       "4   24 January 1966 to 24 March 1977 11 years, 59 ...   \n",
       "5    24 March 1977 to  28 July 1979  2 year, 126 days   \n",
       "6            28 July 1979 to 14 January 1980 170 days   \n",
       "7   14 January 1980 to 31 October 1984 4 years, 29...   \n",
       "8   31 October 1984 to 2 December 1989 5 years, 32...   \n",
       "9        2 December 1989 to 10 November 1990 343 days   \n",
       "10          10 November 1990 to 21 June 1991 223 days   \n",
       "11      21 June 1991 to 16 May 1996 4 years, 330 days   \n",
       "12                 16 May 1996 to 1 June 1996 16 days   \n",
       "13              1 June 1996 to 21 April 1997 324 days   \n",
       "14           21 April 1997 to 19 March 1998  332 days   \n",
       "15     19 March 1998 to 22 May 2004  6 years, 64 days   \n",
       "16     22 May 2004 to 26 May 2014    10 years, 4 days   \n",
       "17                                 26 May 2014 - 2019   \n",
       "18                             30 May 2019- Incumbent   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from South India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15   The first non-congress PM who completed a ful...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  \n",
       "18  First non-congress PM with two consecutive ten...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe of the scraped data\n",
    "df=pd.DataFrame({'Name':name,'Born-Dead':born_dead,'Term of Office':office_term,'Remarks':remarks})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4cb8b-5152-4675-97cb-3d18b72e41f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c47906f9-8bd2-4c76-bdec-24037565a739",
   "metadata": {},
   "source": [
    "Q8: Write a python program to display list of 50 Most expensive cars in the world \r\n",
    "(i.e. Car name and Price) from https://www.motor1.com/  \r\n",
    "This task will be done in following steps: \r\n",
    "1. First get the webpage https://www.motor1.com/ \r\n",
    "2. Then You have to type in the search bar ‚Äô50 most expensive cars‚Äô \r\n",
    "3. Then click on 50 most expensive cars in the world.. \r\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cdf3bbb-ec79-4c1c-a022-353c4b6246c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the given webpage on autumated chrome\n",
    "driver.get(' https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0135b4b-6aa8-4345-afdb-5cad06fd45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching for 50 most expensive cars in the world\n",
    "input=driver.find_element(By.XPATH,'//input[@class=\"m1-search-panel-input m1-search-form-text\"]')\n",
    "input.send_keys('50 most expensive cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd91b6e2-c43c-47a7-8437-ea43781e6e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'//button[@class=\"m1-search-panel-button m1-search-form-button-animate icon-search-svg\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8ff9b74-7a92-45d1-b90f-4ff7260a3a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=driver.find_element(By.XPATH,'//div[@class=\"item wcom \"]/div/div[1]/h3')\n",
    "result.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf2c9fc7-3956-4f45-8b12-6cc0c3829d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "# scraping the data of 50 most expensive cars in the world from giveb webpage\n",
    "\n",
    "# creating blank lists\n",
    "car_name=[]\n",
    "price=[]\n",
    "\n",
    "# scraping name of 50 most expensive car in the world\n",
    "name_tag=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for n in name_tag[0:50]:\n",
    "    car_name.append(n.text)\n",
    "\n",
    "# scraping price of the 50 most expensive car in the world\n",
    "price_tag=driver.find_elements(By.XPATH,'//div[@class=\"postBody description e-content\"]/p/strong')\n",
    "for p in price_tag:\n",
    "    price.append(p.text.replace('Price: ',''))\n",
    "\n",
    "print(len(car_name),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2573832-39ff-400b-b5a9-aa18513d6c24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aston Martin Valour</td>\n",
       "      <td>$1.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>$1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>$1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>$1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>$2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ferrari Daytona SP3</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>$2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>$2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>$2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>$2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>$2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>$2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zenvo Aurora</td>\n",
       "      <td>$2.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>$3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>$3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>$3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>$3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>$3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>$4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>$4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Pininfarina B95 Speedster</td>\n",
       "      <td>$4.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>$5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>$5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>$5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>$6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>$7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>777 Hypercar</td>\n",
       "      <td>$7.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>$8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>$9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Chiron Profil√©e</td>\n",
       "      <td>$10.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>$12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>$13.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>$28.0 Million (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce La Rose Noire Droptail</td>\n",
       "      <td>$30 Million (est.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Car Name                 Price\n",
       "0                  Aston Martin Valour          $1.5 Million\n",
       "1                         McLaren Elva          $1.7 Million\n",
       "2                          Czinger 21C          $1.7 Million\n",
       "3                        Ferrari Monza          $1.7 Million\n",
       "4                   Gordon Murray T.33          $1.7 Million\n",
       "5                    Koenigsegg Gemera          $1.7 Million\n",
       "6                          Zenvo TSR-S          $1.7 Million\n",
       "7                   Hennessey Venom F5          $1.8 Million\n",
       "8                      Bentley Bacalar          $1.9 Million\n",
       "9        Hispano Suiza Carmen Boulogne          $1.9 Million\n",
       "10              Bentley Mulliner Batur          $2.0 Million\n",
       "11                        Deus Vayanne          $2.0 Million\n",
       "12                         SSC Tuatara          $2.0 Million\n",
       "13                         Lotus Evija          $2.1 Million\n",
       "14                 Aston Martin Vulcan          $2.3 Million\n",
       "15                          Delage D12          $2.3 Million\n",
       "16                 Ferrari Daytona SP3          $2.3 Million\n",
       "17                   McLaren Speedtail          $2.3 Million\n",
       "18                        Rimac Nevera          $2.4 Million\n",
       "19                       Pagani Utopia          $2.5 Million\n",
       "20                Pininfarina Battista          $2.5 Million\n",
       "21                  Gordon Murray T.50          $2.6 Million\n",
       "22                Lamborghini Countach          $2.6 Million\n",
       "23            Mercedes-AMG Project One          $2.7 Million\n",
       "24                        Zenvo Aurora          $2.8 Million\n",
       "25                 Aston Martin Victor          $3.0 Million\n",
       "26         Hennessey Venom F5 Roadster          $3.0 Million\n",
       "27                    Koenigsegg Jesko          $3.0 Million\n",
       "28               Aston Martin Valkyrie          $3.2 Million\n",
       "29           W Motors Lykan Hypersport          $3.4 Million\n",
       "30                       McLaren Solus          $3.5 Million\n",
       "31                    Lamborghini Sian          $3.6 million\n",
       "32                    Koenigsegg CC850          $3.7 Million\n",
       "33     Bugatti Chiron Super Sport 300+          $3.9 Million\n",
       "34                  Lamborghini Veneno          $4.5 Million\n",
       "35                      Bugatti Bolide          $4.7 Million\n",
       "36           Pininfarina B95 Speedster          $4.8 Million\n",
       "37                     Bugatti Mistral          $5.0 Million\n",
       "38                 Pagani Huayra Imola          $5.4 Million\n",
       "39                        Bugatti Divo          $5.8 Million\n",
       "40                 SP Automotive Chaos          $6.4 Million\n",
       "41                    Pagani Codalunga          $7.4 Million\n",
       "42                        777 Hypercar          $7.5 Million\n",
       "43            Mercedes-Maybach Exelero          $8.0 Million\n",
       "44                  Bugatti Centodieci          $9.0 Million\n",
       "45             Bugatti Chiron Profil√©e         $10.8 Million\n",
       "46                Rolls-Royce Sweptail         $12.8 Million\n",
       "47            Bugatti La Voiture Noire         $13.4 Million\n",
       "48              Rolls-Royce Boat Tail*  $28.0 Million (est.)\n",
       "49  Rolls-Royce La Rose Noire Droptail    $30 Million (est.)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe of the scraped data of 50 most expensive car in the world from given webpage\n",
    "df=pd.DataFrame({'Car Name':car_name,'Price':price})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
